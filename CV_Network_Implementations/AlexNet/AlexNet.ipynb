{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06d1499",
   "metadata": {},
   "source": [
    "# AlexNet\n",
    "In this, I will be attempting to reimplement AlexNet using PyTorch. The data loading part of this implementation is taken from https://github.com/dansuh17/alexnet-pytorch/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39bd3a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# importing torch and torchvision methods\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torch.utils import data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "# modules for dataset transformation/processing\n",
    "from torch import nn, optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# importing basic plotting + computation libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# file management library\n",
    "import os\n",
    "\n",
    "# checking if GPU available for training\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ee5cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining constants\n",
    "NUM_EPOCHS = 90\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "MOMENTUM = 0.9\n",
    "LR_DECAY = 0.0005\n",
    "LR_INIT = 0.01\n",
    "\n",
    "IMAGE_DIM = 227\n",
    "NUM_CLASSES = 1000  # 1000 classes for imagenet 2012 dataset\n",
    "\n",
    "# modify this to point to your data directory\n",
    "INPUT_ROOT_DIR = 'alexnet_data_in'\n",
    "TRAIN_IMG_DIR = 'alexnet_data_in/imagenet'\n",
    "OUTPUT_DIR = 'alexnet_data_out'\n",
    "LOG_DIR = OUTPUT_DIR + '/tblogs'  # tensorboard logs\n",
    "CHECKPOINT_DIR = OUTPUT_DIR + '/models'  # model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a25cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the network structure\n",
    "class AlexNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=1000):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "    \n",
    "        # calling parent constructor        \n",
    "        super().__init__()\n",
    "        \n",
    "        # compsition of convolutional + maxpooling + activation layers\n",
    "        self.extract_features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=96, stride=4, kernel_size=11, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        \n",
    "        # composition of linear classification layers\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=256 * 6 * 6, out_features=4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=4096, out_features=4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=4096, out_features=1000)\n",
    "        )\n",
    "        \n",
    "        self.init_bias()\n",
    "        \n",
    "        # defining the network in terms of individual layers\n",
    "        \"\"\"\n",
    "        self.cnv1 = nn.Conv2d(in_channels=3, out_channels=96, stride=4, kernel_size=11, padding=0)\n",
    "        self.mp = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.cnv2 = nn.Conv2d(in_channels=96, out_channels=256,kernel_size=5, padding=2, stride=1)\n",
    "        self.cnv3 = nn.Conv2d(in_channels=256, out_channels=384,kernel_size=3, padding=1, stride=1)\n",
    "        self.cnv4 = nn.Conv2d(in_channels=384, out_channels=384,kernel_size=3, padding=1, stride=1)\n",
    "        self.cnv5 = nn.Conv2d(in_channels=384, out_channels=256,kernel_size=3, padding=1, stride=1)\n",
    "        self.fc1 = nn.Linear(in_features=9216, out_features=4096)\n",
    "        self.fc2 = nn.Linear(in_features=4096, out_features=4096)\n",
    "        self.fc3 = nn.Linear(in_features=4096, out_features=10)\n",
    "        \"\"\"\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.extract_features(x)\n",
    "        x = x.view(-1, 256 *6 * 6)\n",
    "        x = self.MLP(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        # original definition of the forward propogation with individual layer defs\n",
    "        \"\"\"\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.mp(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.mp(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.mp(x)\n",
    "        \n",
    "        x = x.reshape(x.shape[0],-1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "        \"\"\"\n",
    "        \n",
    "    def init_bias(self):\n",
    "        for layer in self.extract_features:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                nn.init.normal_(layer.weight, mean=0, std=0.01)\n",
    "                nn.init.constant_(layer.bias, 0)\n",
    "        # original paper = 1 for Conv2d layers 2nd, 4th, and 5th conv layers\n",
    "        nn.init.constant_(self.extract_features[4].bias, 1)\n",
    "        nn.init.constant_(self.extract_features[10].bias, 1)\n",
    "        nn.init.constant_(self.extract_features[12].bias, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e9faf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "\n",
    "\n",
    "# getting an initial seed\n",
    "seed = torch.initial_seed()\n",
    "\n",
    "tbwriter = SummaryWriter(log_dir=LOG_DIR)\n",
    "\n",
    "# loading the model\n",
    "alexnet = AlexNet(num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "# using dataloaders\n",
    "dataset = datasets.ImageFolder(TRAIN_IMG_DIR, transforms.Compose([\n",
    "    transforms.CenterCrop(IMAGE_DIM),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "]))\n",
    "\n",
    "dataloader = data.DataLoader(\n",
    "    dataset,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=8,\n",
    "    drop_last=True,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e73ed79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the optimizer\n",
    "alexnet = AlexNet()\n",
    "optimizer = optim.Adam(params=alexnet.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b00dd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sbaveja/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tStep: 10 \tLoss: 5.2051 \tAcc: 2\n",
      "Epoch: 1 \tStep: 20 \tLoss: 4.9762 \tAcc: 2\n",
      "Epoch: 1 \tStep: 30 \tLoss: 4.8682 \tAcc: 1\n",
      "Epoch: 1 \tStep: 40 \tLoss: 4.9165 \tAcc: 0\n",
      "Epoch: 1 \tStep: 50 \tLoss: 4.8508 \tAcc: 1\n",
      "Epoch: 1 \tStep: 60 \tLoss: 4.8300 \tAcc: 1\n",
      "Epoch: 1 \tStep: 70 \tLoss: 4.8489 \tAcc: 2\n",
      "Epoch: 1 \tStep: 80 \tLoss: 4.8593 \tAcc: 1\n",
      "Epoch: 1 \tStep: 90 \tLoss: 4.8713 \tAcc: 0\n",
      "Epoch: 1 \tStep: 100 \tLoss: 4.8782 \tAcc: 0\n",
      "**********\n",
      "\textract_features.0.weight - grad_avg: 5.494367997016525e-06\n",
      "\textract_features.0.weight - param_avg: -0.00045165038318373263\n",
      "\textract_features.0.bias - grad_avg: -2.3085005977918627e-06\n",
      "\textract_features.0.bias - param_avg: 0.0004981197998858988\n",
      "\textract_features.4.weight - grad_avg: 2.3501314672103035e-07\n",
      "\textract_features.4.weight - param_avg: -0.0007400429458357394\n",
      "\textract_features.4.bias - grad_avg: 1.7282565067944233e-06\n",
      "\textract_features.4.bias - param_avg: 0.9992239475250244\n",
      "\textract_features.8.weight - grad_avg: 3.1269598821381805e-07\n",
      "\textract_features.8.weight - param_avg: -0.00035247585037723184\n",
      "\textract_features.8.bias - grad_avg: 3.6439993778003554e-07\n",
      "\textract_features.8.bias - param_avg: -0.00038667579065077007\n",
      "\textract_features.10.weight - grad_avg: 9.268608778256748e-07\n",
      "\textract_features.10.weight - param_avg: -0.0001656291715335101\n",
      "\textract_features.10.bias - grad_avg: 1.5702093151048757e-05\n",
      "\textract_features.10.bias - param_avg: 0.9994003772735596\n",
      "\textract_features.12.weight - grad_avg: 3.847890184260905e-05\n",
      "\textract_features.12.weight - param_avg: -0.000677392294164747\n",
      "\textract_features.12.bias - grad_avg: 5.475284706335515e-05\n",
      "\textract_features.12.bias - param_avg: 0.9992640614509583\n",
      "\tMLP.1.weight - grad_avg: -2.5218182031494507e-07\n",
      "\tMLP.1.weight - param_avg: -0.00011009623267455027\n",
      "\tMLP.1.bias - grad_avg: -1.7047940445991117e-06\n",
      "\tMLP.1.bias - param_avg: -0.00019442020857241005\n",
      "\tMLP.4.weight - grad_avg: -1.964634748219396e-07\n",
      "\tMLP.4.weight - param_avg: -1.7143618606496602e-05\n",
      "\tMLP.4.bias - grad_avg: -1.0964980674543767e-06\n",
      "\tMLP.4.bias - param_avg: -0.00015163312491495162\n",
      "\tMLP.6.weight - grad_avg: -5.82076596124248e-13\n",
      "\tMLP.6.weight - param_avg: -0.0021092917304486036\n",
      "\tMLP.6.bias - grad_avg: 3.725290475403709e-12\n",
      "\tMLP.6.bias - param_avg: -0.0017760623013600707\n",
      "Epoch: 1 \tStep: 110 \tLoss: 4.8515 \tAcc: 3\n",
      "Epoch: 1 \tStep: 120 \tLoss: 4.8879 \tAcc: 1\n",
      "Epoch: 1 \tStep: 130 \tLoss: 4.8720 \tAcc: 0\n",
      "Epoch: 1 \tStep: 140 \tLoss: 4.8495 \tAcc: 2\n",
      "Epoch: 1 \tStep: 150 \tLoss: 4.8140 \tAcc: 2\n",
      "Epoch: 1 \tStep: 160 \tLoss: 4.8039 \tAcc: 6\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'alexnet_data_out/models/alexnet_states_e1.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(CHECKPOINT_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malexnet_states_e\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     50\u001b[0m state \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch,\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_steps\u001b[39m\u001b[38;5;124m'\u001b[39m: total_steps,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m: seed,\n\u001b[1;32m     56\u001b[0m }\n\u001b[0;32m---> 57\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/serialization.py:377\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03mSaves an object to a disk file.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    >>> torch.save(x, buffer)\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    375\u001b[0m _check_dill_version(pickle_module)\n\u001b[0;32m--> 377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/serialization.py:231\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 231\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/serialization.py:212\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'alexnet_data_out/models/alexnet_states_e1.pkl'"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "total_steps=1\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    lr_scheduler.step()\n",
    "    for imgs, classes in dataloader:\n",
    "        imgs, classes = imgs.to(device), classes.to(device)\n",
    "        \n",
    "        output=alexnet(imgs)\n",
    "        loss=F.cross_entropy(output, classes)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        \n",
    "        if total_steps % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                _, preds = torch.max(output, 1)\n",
    "                accuracy = torch.sum(preds == classes)\n",
    "                \n",
    "            print('Epoch: {} \\tStep: {} \\tLoss: {:.4f} \\tAcc: {}'\n",
    "                            .format(epoch + 1, total_steps, loss.item(), accuracy.item()))\n",
    "            tbwriter.add_scalar('loss', loss.item(), total_steps)\n",
    "            tbwriter.add_scalar('accuracy', accuracy.item(), total_steps)\n",
    "        \n",
    "        if total_steps % 100 == 0:\n",
    "                with torch.no_grad():\n",
    "                    # print and save the grad of the parameters\n",
    "                    # also print and save parameter values\n",
    "                    print('*' * 10)\n",
    "                    for name, parameter in alexnet.named_parameters():\n",
    "                        if parameter.grad is not None:\n",
    "                            avg_grad = torch.mean(parameter.grad)\n",
    "                            print('\\t{} - grad_avg: {}'.format(name, avg_grad))\n",
    "                            tbwriter.add_scalar('grad_avg/{}'.format(name), avg_grad.item(), total_steps)\n",
    "                            tbwriter.add_histogram('grad/{}'.format(name),\n",
    "                                    parameter.grad.cpu().numpy(), total_steps)\n",
    "                        if parameter.data is not None:\n",
    "                            avg_weight = torch.mean(parameter.data)\n",
    "                            print('\\t{} - param_avg: {}'.format(name, avg_weight))\n",
    "                            tbwriter.add_histogram('weight/{}'.format(name),\n",
    "                                    parameter.data.cpu().numpy(), total_steps)\n",
    "                            tbwriter.add_scalar('weight_avg/{}'.format(name), avg_weight.item(), total_steps)\n",
    "        \n",
    "        total_steps += 1\n",
    "        \n",
    "    checkpoint_path = os.path.join(CHECKPOINT_DIR, 'alexnet_states_e{}.pkl'.format(epoch + 1))\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'total_steps': total_steps,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'model': alexnet.state_dict(),\n",
    "        'seed': seed,\n",
    "    }\n",
    "    torch.save(state, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e17d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Shivansh Baveja"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "title": "AlexNet Implemented In PyTorch"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
